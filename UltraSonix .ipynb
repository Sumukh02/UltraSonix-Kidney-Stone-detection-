{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cafef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b03554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Path\n",
    "path = 'uv_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843005e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images\n",
    "train_data_dir = os.path.join(path, 'Train')\n",
    "test_data_dir = os.path.join(path, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1828c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b0c3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 images belonging to 2 classes.\n",
      "Found 71 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb3babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Adding convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Adding a second convolutional layer\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  # this converts our feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b4334bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3116fed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.9212 - accuracy: 0.4930 - val_loss: 0.6513 - val_accuracy: 0.5775\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.7492 - accuracy: 0.5352 - val_loss: 0.6019 - val_accuracy: 0.6761\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.5975 - accuracy: 0.7042 - val_loss: 0.5510 - val_accuracy: 0.9014\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.5339 - accuracy: 0.8310 - val_loss: 0.5111 - val_accuracy: 0.7606\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.5024 - accuracy: 0.7183 - val_loss: 0.4068 - val_accuracy: 0.8732\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.3987 - accuracy: 0.8873 - val_loss: 0.2854 - val_accuracy: 0.9437\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2968 - accuracy: 0.9577 - val_loss: 0.2199 - val_accuracy: 0.9296\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2844 - accuracy: 0.8873 - val_loss: 0.1506 - val_accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.3029 - accuracy: 0.8732 - val_loss: 0.1119 - val_accuracy: 0.9718\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1510 - accuracy: 0.9718 - val_loss: 0.1048 - val_accuracy: 0.9859\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1903 - accuracy: 0.9296 - val_loss: 0.0790 - val_accuracy: 0.9859\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1385 - accuracy: 0.9718 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0874 - accuracy: 0.9859 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0782 - accuracy: 0.9859 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0534 - accuracy: 0.9859 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0679 - accuracy: 0.9718 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 3s 990ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1edc729ea70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Training the Model\n",
    "\n",
    "# Assuming train_generator and test_generator are instances of ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Calculate the number of steps per epoch and validation steps based on the dataset size\n",
    "train_steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(test_generator)\n",
    "\n",
    "# Reduce the number of epochs\n",
    "epochs = 20  # You can adjust this based on your observations\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21414f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sumukh's\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Saving the Model\n",
    "model.save('kidney_stone_detection_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b3abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('kidney_stone_detection_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff385ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 148, 148, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 72, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41472)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2654272   \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2664481 (10.16 MB)\n",
      "Trainable params: 2664481 (10.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79c71cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 720ms/step - loss: 0.0098 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009769842028617859, 1.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Assuming you have a test dataset stored in a directory called 'test_data'\n",
    "test_data_directory = 'C:\\\\Users\\\\Sumukh\\'s\\\\Desktop\\\\BE_Project\\\\Kidney-Stone-Detection-main\\\\uv_images\\\\Test'\n",
    "\n",
    "# Create a test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Or any other preprocessing steps\n",
    "\n",
    "# Flow test data from the directory using the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size=(150, 150),  # Specify the target size of your input images\n",
    "    batch_size=32,  # Adjust batch size according to your requirements\n",
    "    class_mode='binary',  # Set class_mode to 'binary' or 'categorical' depending on your problem\n",
    "    shuffle=False  # Set shuffle to False if you want to evaluate in order\n",
    ")\n",
    "\n",
    "# Use the test generator in the model.evaluate() function\n",
    "model.evaluate(test_generator, steps=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe5cc5",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08a017d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy after tuning: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Modules\n",
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... (previous code for reading images and defining functions)\n",
    "\n",
    "# Combining the features for both classes\n",
    "features = feature_list_normal + feature_list_stone\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# Splitting the data into train and valid sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features_standardized, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': ['auto', 'scale', 0.01, 0.1, 1, 10],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# Create the SVM model with custom kernel\n",
    "def custom_kernel(img1, img2):\n",
    "    # Implement your custom kernel function here\n",
    "    # You might consider preprocessing ultrasound images differently\n",
    "    return np.dot(img1.flatten(), img2.flatten())\n",
    "\n",
    "svm_model = SVC(kernel=custom_kernel)\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predicting the Test Set with the best model\n",
    "X_valid_standardized = scaler.transform(X_valid)\n",
    "y_pred = grid_search.best_estimator_.predict(X_valid_standardized)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Accuracy after tuning:\", accuracy)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(grid_search.best_estimator_, 'svc_tuned.pkl')\n",
    "\n",
    "# Load the tuned SVM model\n",
    "svm_load = joblib.load(\"svc_tuned.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing the required Modules\n",
    "# import cv2 \n",
    "# import numpy as np \n",
    "# from skimage.feature import hog \n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score \n",
    "# import matplotlib.pyplot as plt \n",
    "# from sklearn.model_selection import train_test_split \n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761971dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to read images from the train and test folders\n",
    "def read_images(path):\n",
    "    images_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path,filename))\n",
    "        if img is not None:\n",
    "            images_list.append(img)\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118411cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading train images from the normal and stone folders\n",
    "train_normal = read_images('C:\\\\Users\\\\Sumukh\\'s\\\\Desktop\\\\BE_Project\\\\Kidney-Stone-Detection-main\\\\uv_images\\\\Train\\\\Normal')\n",
    "train_stone = read_images('C:\\\\Users\\\\Sumukh\\'s\\\\Desktop\\\\BE_Project\\\\Kidney-Stone-Detection-main\\\\uv_images\\\\Train\\\\Stones')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of labels for training \n",
    "labels = ['Normal' for item in train_normal] + ['Stone' for item in train_stone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function for HOG feature extraction\n",
    "def extract_features(images):\n",
    "    feature_list = []\n",
    "    for img in images:\n",
    "        fd, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), \n",
    "                            cells_per_block=(1, 1), visualize=True, channel_axis=2)\n",
    "        # Resize the HOG features to a fixed size\n",
    "        fd = np.resize(fd, (2400, 1))\n",
    "        # Flatten the array to 2 dimensions\n",
    "        fd = fd.flatten()\n",
    "        feature_list.append(fd)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54dfc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the HOG features from both normal and stone images\n",
    "feature_list_normal = extract_features(train_normal)\n",
    "feature_list_stone = extract_features(train_stone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c27a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_list_normal))\n",
    "print(len(feature_list_stone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the features for both classes\n",
    "features = feature_list_normal + feature_list_stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading test images from the normal and stone folders\n",
    "test_normal = read_images('C:\\\\Users\\\\Sumukh\\'s\\\\Desktop\\\\BE_Project\\\\Kidney-Stone-Detection-main\\\\uv_images\\\\Test\\\\Normal')\n",
    "test_stone = read_images('C:\\\\Users\\\\Sumukh\\'s\\\\Desktop\\\\BE_Project\\\\Kidney-Stone-Detection-main\\\\uv_images\\\\Test\\\\Stones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43387cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of labels for testing \n",
    "test_labels = ['Normal' for item in test_normal] + ['Stone' for item in test_stone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Feature Vector for Test Set\n",
    "test_feature_list_normal = extract_features(test_normal)\n",
    "test_feature_list_stone = extract_features(test_stone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f22da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(test_feature_list_normal))\n",
    "print(len(test_feature_list_stone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the features for both classes\n",
    "test_features = test_feature_list_normal + test_feature_list_stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and valid sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400,)\n",
      "(2400,)\n",
      "(2400,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the first element in the X_train array\n",
    "print(X_train[0].shape)\n",
    "\n",
    "# Print the shape of the second element in the X_train array\n",
    "print(X_train[1].shape)\n",
    "\n",
    "# Print the shape of the last element in the X_train array\n",
    "print(X_train[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1212b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma='auto')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a SVM Model\n",
    "svc = SVC(kernel='rbf', C=1, gamma='auto')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set\n",
    "y_pred = svc.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf0973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1a7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc1.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.externals\n",
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(svc, 'svc1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.externals\n",
    "import joblib\n",
    "svm_load = joblib.load(\"svc1.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0c4f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Raw Prediction: [[0.00380866]]\n",
      "Raw Prediction: ['Normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Raw Prediction: [[0.99984837]]\n",
      "Raw Prediction: ['Normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Raw Prediction: [[0.9999889]]\n",
      "Raw Prediction: ['Stone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Raw Prediction: [[0.9959405]]\n",
      "Raw Prediction: ['Stone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Raw Prediction: [[0.99947935]]\n",
      "Raw Prediction: ['Stone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Raw Prediction: [[0.00071091]]\n",
      "Raw Prediction: ['Normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Raw Prediction: [[0.00012598]]\n",
      "Raw Prediction: ['Normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "Raw Prediction: [[0.9999889]]\n",
      "Raw Prediction: ['Stone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Raw Prediction: [[0.0015402]]\n",
      "Raw Prediction: ['Normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Raw Prediction: [[0.00086642]]\n",
      "Raw Prediction: ['Normal']\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Raw Prediction: [[0.00086642]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "Raw Prediction: [[0.9997878]]\n",
      "Raw Prediction: ['Stone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Raw Prediction: [[0.00150191]]\n",
      "Raw Prediction: ['Normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Raw Prediction: [[0.00093561]]\n",
      "Raw Prediction: ['Normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Raw Prediction: [[0.9998614]]\n",
      "Raw Prediction: ['Stone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Exception ignored in: <function PhotoImage.__del__ at 0x000001ED80272B00>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sumukh's\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\ImageTk.py\", line 133, in __del__\n",
      "    name = self.__photo.name\n",
      "AttributeError: 'PhotoImage' object has no attribute '_PhotoImage__photo'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sumukh's\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py\", line 3135, in open\n",
      "    fp.seek(0)\n",
      "AttributeError: 'str' object has no attribute 'seek'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sumukh's\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Sumukh's\\AppData\\Local\\Temp\\ipykernel_14472\\2327085567.py\", line 22, in browse_btn\n",
      "    img = Image.open(image_name)\n",
      "  File \"c:\\Users\\Sumukh's\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py\", line 3137, in open\n",
      "    fp = io.BytesIO(fp.read())\n",
      "AttributeError: 'str' object has no attribute 'read'\n"
     ]
    }
   ],
   "source": [
    "# # Creating the GUI\n",
    "# from tkinter import *\n",
    "# from PIL import Image, ImageTk\n",
    "# from tkinter import filedialog\n",
    "# from tkinter.filedialog import askopenfilename\n",
    "# import keras.utils as image\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# root = Tk()\n",
    "# root.geometry('420x380')\n",
    "# root.title('Kidney Stone Detection')\n",
    "\n",
    "# # Function to Select Image\n",
    "# def browse_btn():\n",
    "#     global image_name\n",
    "    \n",
    "#     label_cnn.configure(text=\"\")\n",
    "#     label.configure(text=\"\")\n",
    "    \n",
    "#     image_name = askopenfilename(title='Select Image')\n",
    "#     img = Image.open(image_name)\n",
    "#     img = img.resize((200, 200), Image.ANTIALIAS)\n",
    "#     img = ImageTk.PhotoImage(img)\n",
    "#     panel = Label(root, image=img)\n",
    "#     panel.image = img\n",
    "#     panel.grid(row=0, column=1, sticky='nw', padx=20, pady=28)\n",
    "\n",
    "# # Function to Predict CNN\n",
    "# # def predict_btn_cnn():\n",
    "# #     global label_cnn\n",
    "# #     global image_name\n",
    "# #     test_img = image.load_img(image_name, target_size=(150, 150))\n",
    "# #     test_img = image.img_to_array(test_img)\n",
    "# #     test_img = np.expand_dims(test_img, axis=0)\n",
    "# #     result = model.predict(test_img)\n",
    "# #     if result[0][0] == 1:\n",
    "# #         label_cnn.configure(text=\"Kidney Stone Detected\")\n",
    "# #     elif result[0][0] == 0:\n",
    "# #         label_cnn.configure(text=\"No Kidney Stone Detected\")\n",
    "#     from keras.preprocessing import image\n",
    "\n",
    "# # Function for Predict CNN\n",
    "# def predict_btn_cnn():\n",
    "#     global label_cnn\n",
    "#     global image_name\n",
    "    \n",
    "#     # Load and preprocess the image\n",
    "#     test_img = image.load_img(image_name, target_size=(150, 150))\n",
    "#     test_img = image.img_to_array(test_img)\n",
    "#     test_img = np.expand_dims(test_img, axis=0)\n",
    "#     test_img = test_img / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "#     # Predict\n",
    "#     result = model.predict(test_img)\n",
    "\n",
    "#     # Print the raw prediction for debugging\n",
    "#     print(\"Raw Prediction:\", result)\n",
    "\n",
    "#     # Displaying the output\n",
    "#     if result[0][0] > 0.5:  # Assuming 0.5 as the threshold for binary classification\n",
    "#         label_cnn.configure(text=\"Kidney Stone Detected\")\n",
    "#     else:\n",
    "#         label_cnn.configure(text=\"No Kidney Stone Detected\")\n",
    "\n",
    "\n",
    "# # Function for Predict SVM\n",
    "# # def predict_btn_svm():\n",
    "# #     global label\n",
    "# #     global image_name\n",
    "# #     test_img = cv2.imread(image_name)\n",
    "# #     # test_img = image.load_img(image_name, target_size=(150, 150))\n",
    "# #     # test_img = image.img_to_array(test_img)\n",
    "# #     feature_list_of_img = extract_features([test_img])\n",
    "# #     result = svm_load.predict(feature_list_of_img)\n",
    "# #     # Displaying the output\n",
    "# #     if result[0] == 'Stone':\n",
    "# #         label.configure(text=\"Kidney Stone Detected\")\n",
    "# #     elif result[0] == 'Normal':\n",
    "# #         label.configure(text=\"No Kidney Stone Detected\")\n",
    "#         # Function for Predict SVM\n",
    "# def predict_btn_svm():\n",
    "#     global label\n",
    "#     global image_name\n",
    "#     test_img = cv2.imread(image_name)\n",
    "    \n",
    "#     # Extract features\n",
    "#     feature_list_of_img = extract_features([test_img])\n",
    "    \n",
    "#     # Standardize features if needed\n",
    "#     feature_list_of_img_standardized = scaler.transform(feature_list_of_img)\n",
    "    \n",
    "#     # Predict\n",
    "#     result = svm_load.predict(feature_list_of_img_standardized)\n",
    "    \n",
    "#     # Print the raw prediction for debugging\n",
    "#     print(\"Raw Prediction:\", result)\n",
    "    \n",
    "#     # Displaying the output\n",
    "#     if result[0] == 'Stone':\n",
    "#         label.configure(text=\"Kidney Stone Detected\")\n",
    "#     elif result[0] == 'Normal':\n",
    "#         label.configure(text=\"No Kidney Stone Detected\")\n",
    "\n",
    "\n",
    "# # Browse Button\n",
    "# browsebtn = Button(master=root, text=\"Browse Image\", command=browse_btn)\n",
    "# browsebtn.grid(row=0, column=0, sticky='nw', padx=20, pady=20)\n",
    "\n",
    "# # Predict Button CNN\n",
    "# predictbtn = Button(master=root, text=\"Predict CNN\", command=predict_btn_cnn)\n",
    "# predictbtn.grid(row=1, column=0, sticky='nw', padx=20, pady=20)\n",
    "\n",
    "# # Label Result CNN\n",
    "# label_cnn = Label(root, text=\"\")\n",
    "# label_cnn.grid(row=1, column=1, sticky='nw', padx=20, pady=20)\n",
    "\n",
    "# # Label Result SVM\n",
    "# label = Label(root, text=\"\")\n",
    "# label.grid(row=2, column=1, sticky='nw', padx=20, pady=20)\n",
    "\n",
    "# # Predict Button SVM\n",
    "# predictbtnsvm = Button(master=root, text=\"Predict SVM\", command=predict_btn_svm)\n",
    "# predictbtnsvm.grid(row=2, column=0, sticky='nw', padx=20, pady=20)\n",
    "\n",
    "# # Running the GUI\n",
    "# root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
